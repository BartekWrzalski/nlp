{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartek/SZT/Sem2/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline, DataCollatorWithPadding, Trainer, TrainingArguments, BertForSequenceClassification, pipeline\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, TaskType, get_peft_model\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'input_text'],\n",
      "        num_rows: 853\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'input_text'],\n",
      "        num_rows: 212\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data_files = {\"train\": \"train.jsonl\", \"test\": \"test.jsonl\"}\n",
    "dataset = load_dataset(\"gretelai/symptom_to_diagnosis\", data_files=data_files)\n",
    "dataset = dataset.rename_column(\"output_text\", \"label\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: I've been having a lot of pain in my neck and back. I've also been having trouble with my balance and coordination. I've been coughing a lot and my limbs feel weak. \n",
      "OUTPUT: cervical spondylosis\n",
      "\n",
      "INPUT: I have a rash on my face that is getting worse. It is red, inflamed, and has blisters that are bleeding clear pus. It is really painful. \n",
      "OUTPUT: impetigo\n",
      "\n",
      "INPUT: I have been urinating blood. I sometimes feel sick to my stomach when I urinate. I often feel like I have a fever. \n",
      "OUTPUT: urinary tract infection\n",
      "\n",
      "INPUT: I have been having trouble with my muscles and joints. My neck is really tight and my muscles feel weak. I have swollen joints and it is hard to move around without becoming stiff. It is also really uncomfortable to walk. \n",
      "OUTPUT: arthritis\n",
      "\n",
      "INPUT: I have been feeling really sick. My body hurts a lot and I have no appetite. I have also developed rashes on my arms and face. The back of my eyes hurt a lot. \n",
      "OUTPUT: dengue\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for entry in dataset['train'].select(range(5)):\n",
    "    print('INPUT: {} \\nOUTPUT: {}\\n'.format(entry['input_text'], entry['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allergy</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bronchial asthma</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cervical spondylosis</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chicken pox</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>common cold</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dengue</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>drug reaction</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fungal infection</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gastroesophageal reflux disease</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hypertension</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>impetigo</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>jaundice</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>malaria</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>migraine</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>peptic ulcer disease</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pneumonia</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>psoriasis</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>typhoid</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>urinary tract infection</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>varicose veins</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Diagnosis  train_set  test_set\n",
       "0                           allergy         40        10\n",
       "1                         arthritis         40        10\n",
       "2                  bronchial asthma         40        10\n",
       "3              cervical spondylosis         40        10\n",
       "4                       chicken pox         40        10\n",
       "5                       common cold         39        10\n",
       "6                            dengue         40        10\n",
       "7                          diabetes         40        10\n",
       "8                     drug reaction         40         8\n",
       "9                  fungal infection         39         9\n",
       "10  gastroesophageal reflux disease         39        10\n",
       "11                     hypertension         40        10\n",
       "12                         impetigo         40        10\n",
       "13                         jaundice         33         7\n",
       "14                          malaria         40        10\n",
       "15                         migraine         32        10\n",
       "16             peptic ulcer disease         37        10\n",
       "17                        pneumonia         37        10\n",
       "18                        psoriasis         40        10\n",
       "19                          typhoid         38         9\n",
       "20          urinary tract infection         39         9\n",
       "21                   varicose veins         40        10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_counts = pd.DataFrame({'Diagnosis': dataset['train']['label']})\n",
    "train_counts = train_counts.groupby('Diagnosis').size().reset_index(name='train_set')\n",
    "\n",
    "test_counts = pd.DataFrame({'Diagnosis': dataset['test']['label']})\n",
    "test_counts = test_counts.groupby('Diagnosis').size().reset_index(name='test_set')\n",
    "\n",
    "train_counts.merge(test_counts, on='Diagnosis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(set(dataset['train']['label']))\n",
    "label2id = dict(zip(sorted_labels, range(0, len(sorted_labels))))\n",
    "id2label = dict(zip(range(0, len(sorted_labels)), sorted_labels))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "foundation_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=len(label2id),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label\n",
    ")\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=foundation_model, tokenizer=tokenizer)\n",
    "predicted_labels = classifier(dataset['test']['input_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foundation Model Accuracy: 4.72%\n"
     ]
    }
   ],
   "source": [
    "test_array = np.asarray(dataset['test']['label'])\n",
    "pred_array = np.asarray([item['label'] for item in predicted_labels])\n",
    "foundation_accuracy = round(sum(test_array == pred_array)*100/len(test_array), 2)\n",
    "print(f\"Foundation Model Accuracy: {foundation_accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): lora.Linear(\n",
      "              (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=768, out_features=64, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=64, out_features=768, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): lora.Linear(\n",
      "              (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=768, out_features=64, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=64, out_features=768, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# adding lora layers\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS, r=64, lora_alpha=1, lora_dropout=0.1\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(foundation_model, lora_config)\n",
    "print(peft_model.bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,376,214 || all params: 111,875,372 || trainable%: 2.1240\n"
     ]
    }
   ],
   "source": [
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': Dataset({\n",
      "    features: ['label', 'input_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 853\n",
      "}), 'test': Dataset({\n",
      "    features: ['label', 'input_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 212\n",
      "})}\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    \"\"\"Preprocess the dataset by returning tokenized examples.\"\"\"\n",
    "    tokens = tokenizer(examples[\"input_text\"], padding=\"max_length\", truncation=True)\n",
    "    tokens['label'] = [label2id[l] for l in examples[\"label\"]]\n",
    "    return tokens\n",
    "\n",
    "splits = ['train', 'test']\n",
    "\n",
    "tokenized_ds = {}\n",
    "\n",
    "for split in splits:\n",
    "    tokenized_ds[split] = dataset[split].map(preprocess_function, batched=True)\n",
    "\n",
    "print(tokenized_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training peft-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartek/SZT/Sem2/venv/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3210' max='3210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3210/3210 11:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.475024</td>\n",
       "      <td>19.811321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.104839</td>\n",
       "      <td>61.320755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.226400</td>\n",
       "      <td>1.259054</td>\n",
       "      <td>54.716981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.226400</td>\n",
       "      <td>0.583535</td>\n",
       "      <td>80.660377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.621400</td>\n",
       "      <td>0.468679</td>\n",
       "      <td>84.905660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.621400</td>\n",
       "      <td>0.336716</td>\n",
       "      <td>90.094340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.621400</td>\n",
       "      <td>0.321819</td>\n",
       "      <td>88.679245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.221200</td>\n",
       "      <td>0.232672</td>\n",
       "      <td>93.867925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.221200</td>\n",
       "      <td>0.247691</td>\n",
       "      <td>93.396226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.079400</td>\n",
       "      <td>0.287866</td>\n",
       "      <td>91.509434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.079400</td>\n",
       "      <td>0.252535</td>\n",
       "      <td>95.283019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.220338</td>\n",
       "      <td>94.811321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.271005</td>\n",
       "      <td>91.981132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.230149</td>\n",
       "      <td>94.339623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.227624</td>\n",
       "      <td>94.811321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3210, training_loss=0.4992301059289142, metrics={'train_runtime': 686.7065, 'train_samples_per_second': 18.632, 'train_steps_per_second': 4.674, 'total_flos': 3460510521077760.0, 'train_loss': 0.4992301059289142, 'epoch': 15.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()*100}\n",
    "\n",
    "\n",
    "# The HuggingFace Trainer class handles the training and eval loop for PyTorch for us.\n",
    "# Read more about it here https://huggingface.co/docs/transformers/main_classes/trainer\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"bert-lora\",\n",
    "        learning_rate=2e-3,\n",
    "        # Reduce the batch size if you don't have enough memory\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        num_train_epochs=15,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=\"none\",\n",
    "    ),\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Starting to train...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name: adapter_config.json; File Size: 0.65KB\n",
      "File Name: README.md; File Size: 4.97KB\n",
      "File Name: adapter_model.safetensors; File Size: 9288.92KB\n"
     ]
    }
   ],
   "source": [
    "peft_bert_model_path = \"fine-tuned-peft-model-weights/\"\n",
    "peft_model.save_pretrained(peft_bert_model_path)\n",
    "\n",
    "# check the size of the saved model\n",
    "for file_name in os.listdir(peft_bert_model_path):\n",
    "    file_size = os.path.getsize(peft_bert_model_path + file_name)\n",
    "    print(f\"File Name: {file_name}; File Size: {file_size / 1024:.2f}KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# when loading peft from file \n",
    "config = PeftConfig.from_pretrained(peft_bert_model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", \n",
    "    num_labels=len(label2id),\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, peft_bert_model_path)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n",
    ")\n",
    "trainer.args.report_to = \"none\"\n",
    "\n",
    "test_predictions = trainer.predict(tokenized_ds['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.81%\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "pred = np.argmax(test_predictions.predictions, axis=1)\n",
    "test_labels = tokenized_ds['test']['label']\n",
    "test_labels = np.array(test_labels)\n",
    "accuracy = np.mean(pred == test_labels)\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
