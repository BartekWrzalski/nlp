{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-2\n",
    "W oparciu o fragmenty kodu załączone do pracy:\n",
    "```\n",
    "@misc{transformers_in_embedding_space,\n",
    "  doi = {10.48550/ARXIV.2209.02535},\n",
    "  url = {https://arxiv.org/abs/2209.02535},\n",
    "  author = {Dar, Guy and Geva, Mor and Gupta, Ankit and Berant, Jonathan},\n",
    "  title = {Analyzing Transformers in Embedding Space},\n",
    "  publisher = {arXiv},\n",
    "  year = {2022},\n",
    "  copyright = {Creative Commons Attribution 4.0 International}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append(\"/net/software/v1/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModel\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm, trange\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "ALNUM_CHARSET = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789')\n",
    "\n",
    "def convert_to_tokens(indices, tokenizer, extended=False, extra_values_pos=None, strip=True):\n",
    "    if extended:\n",
    "        res = [tokenizer.convert_ids_to_tokens([idx])[0] if idx < len(tokenizer) else \n",
    "               (f\"[pos{idx-len(tokenizer)}]\" if idx < extra_values_pos else f\"[val{idx-extra_values_pos}]\") \n",
    "               for idx in indices]\n",
    "    else:\n",
    "        res = tokenizer.convert_ids_to_tokens(indices)\n",
    "    if strip:\n",
    "        res = list(map(lambda x: x[1:] if x[0] == 'Ġ' else \"#\" + x, res))\n",
    "    return res\n",
    "\n",
    "\n",
    "def top_tokens(v, k=100, tokenizer=None, only_alnum=False, only_ascii=True, with_values=False, \n",
    "               exclude_brackets=False, extended=True, extra_values=None, only_from_list=None):\n",
    "    v = deepcopy(v)\n",
    "    ignored_indices = []\n",
    "    if only_ascii:\n",
    "        ignored_indices.extend([key for val, key in tokenizer.vocab.items() if not val.strip('Ġ▁').isascii()])\n",
    "    if only_alnum: \n",
    "        ignored_indices.extend([key for val, key in tokenizer.vocab.items() if not (set(val.strip('Ġ▁[] ')) <= ALNUM_CHARSET)])\n",
    "    if only_from_list:\n",
    "        ignored_indices.extend([key for val, key in tokenizer.vocab.items() if val.strip('Ġ▁ ').lower() not in only_from_list])\n",
    "    if exclude_brackets:\n",
    "        ignored_indices = set(ignored_indices).intersection(\n",
    "            {key for val, key in tokenizer.vocab.items() if not (val.isascii() and val.isalnum())})\n",
    "        ignored_indices = list(ignored_indices)\n",
    "        \n",
    "    ignored_indices = list(set(ignored_indices))\n",
    "    v[ignored_indices] = -np.inf\n",
    "    extra_values_pos = len(v)\n",
    "    if extra_values is not None:\n",
    "        v = torch.cat([v, extra_values])\n",
    "    values, indices = torch.topk(v, k=k)\n",
    "    res = convert_to_tokens(indices, tokenizer, extended=extended, extra_values_pos=extra_values_pos)\n",
    "    if with_values:\n",
    "        res = list(zip(res, values.cpu().numpy()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_topk(mat, min_k=500, max_k=250_000, th0=10, max_iters=10, verbose=False):\n",
    "    _get_actual_k = lambda th, th_max: torch.nonzero((mat > th) & (mat < th_max)).shape[0]\n",
    "    th_max = np.inf\n",
    "    left, right = 0, th0 \n",
    "    while True:\n",
    "        actual_k = _get_actual_k(right, th_max)\n",
    "        if verbose:\n",
    "            print(f\"one more iteration. {actual_k}\")\n",
    "        if actual_k <= max_k:\n",
    "            break\n",
    "        left, right = right, right * 2\n",
    "    if min_k <= actual_k <= max_k:\n",
    "        th = right\n",
    "    else:\n",
    "        for _ in range(max_iters):\n",
    "            mid = (left + right) / 2\n",
    "            actual_k = _get_actual_k(mid, th_max)\n",
    "            if verbose:\n",
    "                print(f\"one more iteration. {actual_k}\")\n",
    "            if min_k <= actual_k <= max_k:\n",
    "                break\n",
    "            if actual_k > max_k:\n",
    "                left = mid\n",
    "            else:\n",
    "                right = mid\n",
    "        th = mid\n",
    "    return torch.nonzero((mat > th) & (mat < th_max)).tolist()\n",
    "\n",
    "def get_top_entries(tmp, all_high_pos, only_ascii=False, only_alnum=False, exclude_same=False, exclude_fuzzy=False, tokens_list=None, tokenizer=None, reverse_list=False):\n",
    "    remaining_pos = all_high_pos\n",
    "    if only_ascii:\n",
    "        remaining_pos = [*filter(\n",
    "            lambda x: (tokenizer.decode(x[0]).strip('Ġ▁').isascii() and tokenizer.decode(x[1]).strip('Ġ▁').isascii()), \n",
    "            remaining_pos)]\n",
    "    if only_alnum:\n",
    "        remaining_pos = [*filter(\n",
    "            lambda x: (tokenizer.decode(x[0]).strip('Ġ▁ ').isalnum() and tokenizer.decode(x[1]).strip('Ġ▁ ').isalnum()), \n",
    "            remaining_pos)]\n",
    "    if exclude_same:\n",
    "        remaining_pos = [*filter(\n",
    "            lambda x: tokenizer.decode(x[0]).lower().strip() != tokenizer.decode(x[1]).lower().strip(), \n",
    "            remaining_pos)]\n",
    "    if exclude_fuzzy:\n",
    "        remaining_pos = [*filter(\n",
    "            lambda x: not _fuzzy_eq(tokenizer.decode(x[0]).lower().strip(), tokenizer.decode(x[1]).lower().strip()), \n",
    "            remaining_pos)]\n",
    "    if tokens_list:\n",
    "        remaining_pos = [*filter(\n",
    "            lambda x: ((tokenizer.decode(x[0]).strip('Ġ▁').lower().strip() in tokens_list) and \n",
    "                       (tokenizer.decode(x[1]).strip('Ġ▁').lower().strip() in tokens_list)), \n",
    "            remaining_pos)]\n",
    "\n",
    "    pos_val = tmp[[*zip(*remaining_pos)]]\n",
    "    good_cells = [*map(lambda x: (tokenizer.decode(x[0]), tokenizer.decode(x[1])), remaining_pos)]\n",
    "    good_tokens = list(map(lambda x: Counter(x).most_common(), zip(*good_cells)))\n",
    "    remaining_pos_best = np.array(remaining_pos)[torch.argsort(pos_val if reverse_list else -pos_val)[:50]]\n",
    "    good_cells_best = [*map(lambda x: (tokenizer.decode(x[0]), tokenizer.decode(x[1])), remaining_pos_best)]\n",
    "    # good_cells[:100]\n",
    "    # list(zip(good_tokens[0], good_tokens[1]))\n",
    "    return good_cells_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"sdadas/polish-gpt2-medium\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sdadas/polish-gpt2-medium\")\n",
    "emb = model.get_output_embeddings().weight.data.T.detach()\n",
    "\n",
    "num_layers = model.config.n_layer\n",
    "num_heads = model.config.n_head\n",
    "hidden_dim = model.config.n_embd\n",
    "head_size = hidden_dim // num_heads\n",
    "\n",
    "K = torch.cat([model.get_parameter(f\"transformer.h.{j}.mlp.c_fc.weight\").T\n",
    "                           for j in range(num_layers)]).detach()\n",
    "V = torch.cat([model.get_parameter(f\"transformer.h.{j}.mlp.c_proj.weight\")\n",
    "                           for j in range(num_layers)]).detach()\n",
    "\n",
    "W_Q, W_K, W_V = torch.cat([model.get_parameter(f\"transformer.h.{j}.attn.c_attn.weight\") \n",
    "                           for j in range(num_layers)]).detach().chunk(3, dim=-1)\n",
    "W_O = torch.cat([model.get_parameter(f\"transformer.h.{j}.attn.c_proj.weight\") \n",
    "                           for j in range(num_layers)]).detach()\n",
    "\n",
    "K_heads = K.reshape(num_layers, -1, hidden_dim)\n",
    "V_heads = V.reshape(num_layers, -1, hidden_dim)\n",
    "d_int = K_heads.shape[1]\n",
    "\n",
    "W_Q_heads = W_Q.reshape(num_layers, hidden_dim, num_heads, head_size).permute(0, 2, 1, 3)\n",
    "W_K_heads = W_K.reshape(num_layers, hidden_dim, num_heads, head_size).permute(0, 2, 1, 3)\n",
    "W_V_heads = W_V.reshape(num_layers, hidden_dim, num_heads, head_size).permute(0, 2, 1, 3)\n",
    "W_O_heads = W_O.reshape(num_layers, num_heads, head_size, hidden_dim)\n",
    "\n",
    "emb_inv = emb.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretacja $W_{VO}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('alam', 'alem'),\n",
       " ('alam', 'lem'),\n",
       " ('skakuje', ' powiedziala'),\n",
       " ('suwa', ' skierowali'),\n",
       " (' pytam', ' powiedziala'),\n",
       " ('puszczam', ' poczuli'),\n",
       " ('puszczam', 'dli'),\n",
       " (' dodaje', 'knal'),\n",
       " (' powinnam', 'ales'),\n",
       " (' pytam', 'stuje'),\n",
       " (' dostajemy', ' dowiedzieli'),\n",
       " ('puszczam', 'cil'),\n",
       " ('suwa', ' poczuli'),\n",
       " ('siadam', 'muje'),\n",
       " (' odpowiadam', ' odpowiedzieli'),\n",
       " ('suwa', ' powiedziala'),\n",
       " ('staje', ' stwierdzili'),\n",
       " ('suwa', ' postanawia'),\n",
       " ('suwa', ' stwierdzili'),\n",
       " ('lewam', 'stuje'),\n",
       " ('alam', 'glem'),\n",
       " ('lewam', ' poznali'),\n",
       " ('lewam', 'dujemy'),\n",
       " (' odpowiadam', 'alia'),\n",
       " ('staje', 'cila'),\n",
       " (' odpowiadam', ' powiedziala'),\n",
       " ('puszczam', ' poznali'),\n",
       " ('lewam', 'cil'),\n",
       " ('mawiam', 'duje'),\n",
       " ('siadam', 'stuje'),\n",
       " ('alam', 'tional'),\n",
       " (' udaje', 'lem'),\n",
       " ('staje', ' powiedziala'),\n",
       " (' wyjmuje', ' wymienili'),\n",
       " ('suwa', 'knal'),\n",
       " (' wyjmuje', ' usiedli'),\n",
       " (' chwyta', ' poczuli'),\n",
       " ('suwa', ' poznali'),\n",
       " ('puszczam', 'duje'),\n",
       " (' wyjmuje', ' powiedziala'),\n",
       " (' powinnam', 'lem'),\n",
       " ('muje', ' postanawia'),\n",
       " (' wyjmuje', ' odpowiedzieli'),\n",
       " ('alam', 'ales'),\n",
       " ('siadam', 'tamy'),\n",
       " ('suwa', ' okazali'),\n",
       " ('staje', ' poczuli'),\n",
       " ('staje', ' postanawia'),\n",
       " (' szepcze', 'dli'),\n",
       " (' dostrzega', ' powiedziala')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer, head = 0, 0\n",
    "\n",
    "W_V_tmp, W_O_tmp = W_V_heads[layer, head, :], W_O_heads[layer, head]\n",
    "tmp = (emb_inv @ (W_V_tmp @ W_O_tmp) @ emb)\n",
    "\n",
    "all_high_pos = approx_topk(tmp, th0=1, verbose=False)\n",
    "\n",
    "get_top_entries(tmp, all_high_pos, only_ascii=True, only_alnum=True, \n",
    "                exclude_same=True, tokens_list=None, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla warstwy 0 i głowy 0 obserwujemy najczęściej pary czasowników."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretacja $W_{KV}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one more iteration. 0\n",
      "one more iteration. 0\n",
      "one more iteration. 16\n",
      "one more iteration. 92784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('dora', 'ario'),\n",
       " ('nta', 'rion'),\n",
       " ('CJE', 'CJ'),\n",
       " ('dora', 'ces'),\n",
       " ('taria', 'lio'),\n",
       " ('ariuszy', 'ariusza'),\n",
       " ('jek', 'rion'),\n",
       " ('KP', 'PL'),\n",
       " ('ariusz', 'ariusza'),\n",
       " ('CJ', 'EL'),\n",
       " (' informacyjnych', ' RPO'),\n",
       " ('erb', 'fin'),\n",
       " ('dora', 'rion'),\n",
       " ('czyn', 'kup'),\n",
       " ('aryj', 'nowo'),\n",
       " ('eu', 'lio'),\n",
       " ('feld', 'dorf'),\n",
       " ('RD', 'AN'),\n",
       " ('PR', 'PL'),\n",
       " ('tari', 'lio'),\n",
       " ('pad', 'pada'),\n",
       " ('BN', 'EL'),\n",
       " (' informacyjnych', ' informacyjne'),\n",
       " ('data', 'dat'),\n",
       " ('dnika', 'kup'),\n",
       " ('czew', 'kup'),\n",
       " ('chta', 'cht'),\n",
       " ('pety', 'ceu'),\n",
       " ('zofre', 'lio'),\n",
       " ('chowie', 'dorf'),\n",
       " ('ariusza', 'ariusz'),\n",
       " ('DE', 'EL'),\n",
       " ('ariusze', 'ariusza'),\n",
       " ('ire', 'lio'),\n",
       " ('czyny', 'kup'),\n",
       " ('RS', 'PL'),\n",
       " ('ariuszy', 'ariuszem'),\n",
       " ('jnie', 'kup'),\n",
       " ('RD', 'IN'),\n",
       " ('ANE', 'EL'),\n",
       " ('lia', 'lio'),\n",
       " ('din', 'der'),\n",
       " ('jek', 'jer'),\n",
       " ('szak', 'eryk'),\n",
       " (' wojennej', ' wojennych'),\n",
       " ('MP', 'IN'),\n",
       " ('kamie', 'mek'),\n",
       " ('eryka', 'eryk'),\n",
       " ('nty', 'chno'),\n",
       " ('KP', 'EL')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer, head = 4, 4\n",
    "\n",
    "W_Q_tmp, W_K_tmp = W_Q_heads[layer, head, :], W_K_heads[layer, head, :]\n",
    "tmp2 = (emb_inv @ (W_Q_tmp @ W_K_tmp.T) @ emb_inv.T)\n",
    "\n",
    "all_high_pos2 = approx_topk(tmp2, th0=1, verbose=True)\n",
    "\n",
    "get_top_entries(tmp2, all_high_pos2, only_ascii=True, only_alnum=True, \n",
    "                exclude_same=True, tokens_list=None, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pary klucz-wartość dla warstwy 4, głowy 4 to pasujące do siebie odmiany (np. \"ariusze\" i \"ariusza\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one more iteration. 0\n",
      "one more iteration. 12\n",
      "one more iteration. 8791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('dzkimi', 'unkami'),\n",
       " (' ktora', ' ktorej'),\n",
       " ('dzkimi', 'nkami'),\n",
       " ('ings', 'tti'),\n",
       " ('nina', 'anina'),\n",
       " (' narodowymi', 'stkami'),\n",
       " ('perze', 'czniku'),\n",
       " (' katolickim', 'leckim'),\n",
       " ('zwykopem', 'czko'),\n",
       " ('ksem', 'nkiem'),\n",
       " ('lotem', 'jazdem'),\n",
       " ('usem', 'jazdem'),\n",
       " ('lnej', 'niowej'),\n",
       " ('zin', 'wei'),\n",
       " ('zwykopem', 'kosz'),\n",
       " ('inga', 'essa'),\n",
       " ('OWIE', 'Wer'),\n",
       " ('towanym', 'tkowski'),\n",
       " ('padzie', 'locie'),\n",
       " (' katolickim', 'tyzmem'),\n",
       " ('perze', 'cianie'),\n",
       " (' rodzinami', 'niakami'),\n",
       " ('burg', 'hoe'),\n",
       " ('dziu', 'niczki'),\n",
       " ('dzkimi', 'onami'),\n",
       " (' sumieniu', 'twor'),\n",
       " (' prokuratorem', 'pieniem'),\n",
       " ('dzkimi', 'chami'),\n",
       " ('usem', 'rusem'),\n",
       " ('padzie', 'pisie'),\n",
       " ('zdni', 'niowej'),\n",
       " ('loty', 'roli'),\n",
       " (' rodzinna', 'arska'),\n",
       " ('osobowa', 'nikowa'),\n",
       " ('onny', 'twor'),\n",
       " ('jsku', 'niuk'),\n",
       " ('szkiem', 'cznemu'),\n",
       " (' religijnym', 'nickim'),\n",
       " ('mieniu', 'manie'),\n",
       " ('gnieniu', 'nalnie'),\n",
       " (' katolickim', 'tage'),\n",
       " ('dziu', 'niczek'),\n",
       " ('grzech', 'manie'),\n",
       " ('dniem', 'nkiem'),\n",
       " (' warta', 'anowa'),\n",
       " ('mieniu', 'mali'),\n",
       " (' kredytowej', 'niowej'),\n",
       " ('szowa', 'wara'),\n",
       " ('dzkimi', 'jazdem'),\n",
       " ('dniem', 'tonem')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer, head = 8, 4\n",
    "\n",
    "W_Q_tmp, W_K_tmp = W_Q_heads[layer, head, :], W_K_heads[layer, head, :]\n",
    "tmp2 = (emb_inv @ (W_Q_tmp @ W_K_tmp.T) @ emb_inv.T)\n",
    "\n",
    "all_high_pos2 = approx_topk(tmp2, th0=1, verbose=True)\n",
    "\n",
    "get_top_entries(tmp2, all_high_pos2, only_ascii=True, only_alnum=True, \n",
    "                exclude_same=True, tokens_list=None, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one more iteration. 0\n",
      "one more iteration. 0\n",
      "one more iteration. 17667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(' wnim', 'pokoju'),\n",
       " (' wdomu', 'pokoju'),\n",
       " (' iroz', 'pokoju'),\n",
       " (' wna', 'pokoju'),\n",
       " (' wnim', 'di'),\n",
       " (' konsumenta', ' konsumen'),\n",
       " (' wtym', 'pokoju'),\n",
       " (' wnim', 'cala'),\n",
       " (' znim', 'pokoju'),\n",
       " (' wtej', 'tara'),\n",
       " (' wtej', 'pokoju'),\n",
       " (' wnim', 'pew'),\n",
       " (' wnim', 'des'),\n",
       " (' itak', 'pokoju'),\n",
       " (' wnim', 'tym'),\n",
       " (' Prezydent', ' RP'),\n",
       " (' wnim', 'tara'),\n",
       " (' iwy', 'pokoju'),\n",
       " (' itak', 'cala'),\n",
       " (' wdomu', 'tara'),\n",
       " (' apotem', 'tara'),\n",
       " (' wmo', 'pokoju'),\n",
       " (' wnim', 'tale'),\n",
       " (' otym', 'wszyscy'),\n",
       " (' iprze', 'pokoju'),\n",
       " (' io', 'pokoju'),\n",
       " (' regulowane', ' reguluje'),\n",
       " (' wjego', 'pokoju'),\n",
       " (' wnim', 'wiel'),\n",
       " (' znim', 'pew'),\n",
       " (' wtej', 'pew'),\n",
       " (' itak', 'di'),\n",
       " (' miasteczka', ' nadmor'),\n",
       " (' Prezydenta', ' RP'),\n",
       " (' znich', 'di'),\n",
       " (' itak', 'tara'),\n",
       " (' wnim', 'jego'),\n",
       " ('finans', ' inwestycyjne'),\n",
       " (' konsument', ' konsumen'),\n",
       " (' iz', 'cala'),\n",
       " (' stowarzyszenia', ' zrzesza'),\n",
       " (' wnim', 'dia'),\n",
       " (' wna', 'tara'),\n",
       " (' znim', 'di'),\n",
       " (' biznesie', ' biznes'),\n",
       " (' ito', 'tara'),\n",
       " (' wtym', 'wszyscy'),\n",
       " (' ito', 'pokoju'),\n",
       " (' nieprzyjaciel', ' nieprzyjaciela'),\n",
       " (' iprzy', 'pokoju')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer, head = 23, 4\n",
    "\n",
    "W_Q_tmp, W_K_tmp = W_Q_heads[layer, head, :], W_K_heads[layer, head, :]\n",
    "tmp2 = (emb_inv @ (W_Q_tmp @ W_K_tmp.T) @ emb_inv.T)\n",
    "\n",
    "all_high_pos2 = approx_topk(tmp2, th0=1, verbose=True)\n",
    "\n",
    "get_top_entries(tmp2, all_high_pos2, only_ascii=True, only_alnum=True, \n",
    "                exclude_same=True, tokens_list=None, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel-venv-3.11",
   "language": "python",
   "name": "kernel-venv-3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
